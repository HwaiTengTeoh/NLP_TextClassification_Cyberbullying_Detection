{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a1ce83",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#fff; color:white; padding:0px 10px; border-radius:5px;\"><h1 style='margin:15px 15px; color:#ff6f69; font-size:40px'>2. Data Cleaning and Preprocessing - Pipeline </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44791b",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#ff6f69; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Prior Requirements</h2>\n",
    "</div>\n",
    "\n",
    "Make sure the followings are installed in Python environment\n",
    "\n",
    "Under Anaconda Prompt :\n",
    "- `Textblob` Package: `!pip install textblob`\n",
    "- `spacy` Package: `!pip install spacy`\n",
    "- Trained pipelines for English under Spacy: `python -m spacy download en`\n",
    "- Consolidated Text Preprocessing package: `!pip install git+ssh://git@github.com/HwaiTengTeoh/pt.git`\n",
    "- `emot` Package: `!pip install emot`\n",
    "- Download `Emoji_Dict.p` from download link: https://drive.google.com/open?id=1G1vIkkbqPBYPKHcQ8qy0G2zkoab2Qv4v\n",
    "- Download `Emoticon_Dict.p` from download link: https://drive.google.com/open?id=1HDpafp97gCl9xZTQWMgP2kKK_NuhENlE\n",
    "- `Gensim` Package: `!pip install gensim`\n",
    "- Spelling Check - `language-tool-python` Package: `!pip install language-tool-python` **(More precise)**\n",
    "- Contraction to Expansion - `pycontractions` Package: `!pip install pycontractions` **(More precise)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494aa141",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#ff6f69; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Import Libraries/ Modules</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75d81dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "%matplotlib inline\n",
    "\n",
    "# Begin Python Imports\n",
    "import datetime, warnings, scipy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# Progress bar\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "# Text Cleaning & Normalization\n",
    "import re\n",
    "import pickle\n",
    "import spacy\n",
    "import nltk\n",
    "from emot.emo_unicode import UNICODE_EMOJI, EMOTICONS_EMO\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d2e0b",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#ff6f69; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Import data</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9ddde79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data \n",
    "bully_data = pd.read_csv('bully_data_toclean_version.csv', encoding='utf8')\n",
    "\n",
    "# Check first 2 instances and last 2 instances\n",
    "# bully_data.head(2).append(bully_data.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec33154",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#ff6f69; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Initial Dataset Exploration</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "670fd28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 113694 rows and 8 columns from the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Check dimension of dataset\n",
    "bully_data.shape\n",
    "print(\"There are \"+ str(bully_data.shape[0]) +\" rows and \"+ str(bully_data.shape[1]) +\" columns from the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd79acc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 113694 entries, 0 to 113693\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Unnamed: 0         113694 non-null  int64  \n",
      " 1   tag                113694 non-null  object \n",
      " 2   text               113694 non-null  object \n",
      " 3   label              113694 non-null  object \n",
      " 4   role               113694 non-null  object \n",
      " 5   harmfulness_score  113694 non-null  float64\n",
      " 6   oth_language       113694 non-null  int64  \n",
      " 7   file_index         113694 non-null  object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check column type\n",
    "bully_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f4b9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Unwanted column\n",
    "bully_data.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9929be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Unwanted column\n",
    "bully_data=bully_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14006f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 113694 entries, 0 to 113693\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   tag                113694 non-null  object \n",
      " 1   text               113694 non-null  object \n",
      " 2   label              113694 non-null  object \n",
      " 3   role               113694 non-null  object \n",
      " 4   harmfulness_score  113694 non-null  float64\n",
      " 5   oth_language       113694 non-null  int64  \n",
      " 6   file_index         113694 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Last check column type\n",
    "bully_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c2c4c",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#ff6f69; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>(Ignore) Handle of missing data - None</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "170c35ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of missing data in columns\n",
      "Empty DataFrame\n",
      "Columns: [column_name, percentage]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Calculate the proportion of missing data\n",
    "\n",
    "def checkMissing(data,perc=0):\n",
    "    \"\"\" \n",
    "    Function that takes in a dataframe and returns\n",
    "    the percentage of missing value.\n",
    "    \"\"\"\n",
    "    missing = [(i, data[i].isna().mean()*100) for i in data]\n",
    "    missing = pd.DataFrame(missing, columns=[\"column_name\", \"percentage\"])\n",
    "    missing = missing[missing.percentage > perc]\n",
    "    print(missing.sort_values(\"percentage\", ascending=False).reset_index(drop=True))\n",
    "\n",
    "print(\"Proportion of missing data in columns\")\n",
    "checkMissing(bully_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b61d3a",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#ff6f69; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Text Preprocessing Pipeline </h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_text as pt\n",
    "import language_tool_python\n",
    "from pycontractions.contractions import Contractions\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instantiate\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "cont = Contractions(api_key=\"glove-twitter-100\")\n",
    "\n",
    "# Functions\n",
    "def get_term_list(path):\n",
    "    '''\n",
    "    Function to import term list file\n",
    "    '''\n",
    "    word_list = []\n",
    "    with open(path,\"r\") as f:\n",
    "        for line in f:\n",
    "            word = line.replace(\"\\n\",\"\").strip()\n",
    "            word_list.append(word)\n",
    "    return word_list\n",
    "\n",
    "def get_vocab(corpus):\n",
    "    '''\n",
    "    Function returns unique words in document corpus\n",
    "    '''\n",
    "    # vocab set\n",
    "    unique_words = set()\n",
    "    \n",
    "    # looping through each document in corpus\n",
    "    for document in tqdm(corpus):\n",
    "        for word in document.split(\" \"):\n",
    "            if len(word) > 2:\n",
    "                unique_words.add(word)\n",
    "    \n",
    "    return unique_words\n",
    "\n",
    "def create_profane_mapping(profane_words,vocabulary):\n",
    "    '''\n",
    "    Function creates a mapping between commonly found profane words and words in \n",
    "    document corpus \n",
    "    '''\n",
    "    \n",
    "    # mapping dictionary\n",
    "    mapping_dict = dict()\n",
    "    \n",
    "    # looping through each profane word\n",
    "    for profane in tqdm(profane_words):\n",
    "        mapped_words = set()\n",
    "        \n",
    "        # looping through each word in vocab\n",
    "        for word in vocabulary:\n",
    "            # mapping only if ratio > 80\n",
    "            try:\n",
    "                if fuzz.ratio(profane,word) > 90:\n",
    "                    mapped_words.add(word)\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        # list of all vocab words for given profane word\n",
    "        mapping_dict[profane] = mapped_words\n",
    "    \n",
    "    return mapping_dict\n",
    "\n",
    "def replace_words(corpus,mapping_dict):\n",
    "    '''\n",
    "    Function replaces obfuscated profane words using a mapping dictionary\n",
    "    '''\n",
    "    \n",
    "    processed_corpus = []\n",
    "    \n",
    "    # iterating over each document in the corpus\n",
    "    for document in tqdm(corpus):\n",
    "        \n",
    "        # splitting sentence to word\n",
    "        comment = document.split()\n",
    "        \n",
    "        # iterating over mapping_dict\n",
    "        for mapped_word,v in mapping_dict.items():\n",
    "            \n",
    "            # comparing target word to each comment word \n",
    "            for target_word in v:\n",
    "                \n",
    "                # each word in comment\n",
    "                for i,word in enumerate(comment):\n",
    "                    if word == target_word:\n",
    "                        comment[i] = mapped_word\n",
    "        \n",
    "        # joining comment words\n",
    "        document = \" \".join(comment)\n",
    "        document = document.strip()\n",
    "                    \n",
    "        processed_corpus.append(document)\n",
    "        \n",
    "    return processed_corpus\n",
    "\n",
    "# Counts of term by category\n",
    "countvec = CountVectorizer(ngram_range=(1,3))\n",
    "def get_term_counts(x,category):\n",
    "    \n",
    "    # Split input text by unigram, bigram and trigram\n",
    "    # as the keywords may span up to 3 words\n",
    "    def get_ngram_text(x):\n",
    "        \n",
    "        try:\n",
    "            countvec.fit_transform(x)\n",
    "            text_list = countvec.get_feature_names()\n",
    "            return text_list\n",
    "\n",
    "        except ValueError:\n",
    "            return [' '] # to handle scenario where text input are all stop words only\n",
    "    \n",
    "    # check the existence of word by category\n",
    "    term_category = [t for t in get_ngram_text(x) if t in category]\n",
    "    \n",
    "    # return the number of occurence\n",
    "    return len(term_category)\n",
    "\n",
    "\n",
    "# Import external list, store as list\n",
    "term_absolute_list = get_term_list(\"term_list/compiled_absolute.txt\")\n",
    "term_allness_list = get_term_list(\"term_list/compiled_allness.txt\")\n",
    "term_badword_list = get_term_list(\"term_list/compiled_badword.txt\")\n",
    "term_negation_list = get_term_list(\"term_list/compiled_negation.txt\")\n",
    "term_diminisher_list = get_term_list(\"term_list/compiled_diminisher.txt\")\n",
    "term_intensifier_list = get_term_list(\"term_list/compiled_intensifier.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cbd4231",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Text Preprocessing Pipeline #\n",
    "###############################\n",
    "\n",
    "def text_preprocessing_pipeline(df=bully_data,\n",
    "                                textual_statistics=False,\n",
    "                                remove_url=False,\n",
    "                                remove_email=False,\n",
    "                                remove_user_mention=False,\n",
    "                                remove_html=False,\n",
    "                                remove_space_single_char=False,\n",
    "                                normalize_elongated_char=False,\n",
    "                                normalize_emoji=False,\n",
    "                                normalize_emoticon=False,\n",
    "                                normalize_accented=False,\n",
    "                                lower_case=False,\n",
    "                                normalize_slang=False,\n",
    "                                normalize_badterm=False,\n",
    "                                spelling_check=False,\n",
    "                                normalize_contraction=False,\n",
    "                                term_list=False,\n",
    "                                remove_numeric=False,\n",
    "                                remove_stopword=False,\n",
    "                                keep_pronoun=False,\n",
    "                                remove_punctuation=False,\n",
    "                                pos=False,\n",
    "                                ner=False,\n",
    "                                lemmatise=False\n",
    "                               ):\n",
    "    '''\n",
    "    -------------\n",
    "     Description\n",
    "    -------------\n",
    "    Function that compile all preprocessing steps in one go\n",
    "    \n",
    "    -----------\n",
    "     Parameter\n",
    "    -----------\n",
    "    df: Data Frame\n",
    "    textual_statistics: Boolean\n",
    "    remove_url: Boolean\n",
    "    remove_email: Boolean\n",
    "    remove_user_mention: Boolean\n",
    "    remove_html: Boolean\n",
    "    remove_space_single_char: Boolean\n",
    "    normalize_elongated_char: Boolean\n",
    "    normalize_emoji: Boolean\n",
    "    normalize_emoticon: Boolean\n",
    "    normalize_accented: Boolean\n",
    "    lower_case: Boolean\n",
    "    normalize_slang: Boolean\n",
    "    normalize_badterm: Boolean\n",
    "    spelling_check: Boolean\n",
    "    normalize_contraction: Boolean\n",
    "    remove_numeric: Boolean\n",
    "    remove_stopword: Boolean\n",
    "    keep_pronoun: Boolean\n",
    "    remove_punctuation: Boolean\n",
    "    pos: Boolean\n",
    "    ner: Boolean\n",
    "    lemmatise: Boolean\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if textual_statistics:\n",
    "        print('Developing textual statistics from original text')\n",
    "        df['word_count'] = df['text'].progress_apply(lambda x: pt.get_wordcounts(x))\n",
    "        df['char_count'] = df['text'].progress_apply(lambda x: pt.get_char_counts(x))\n",
    "        df['avg_word_len'] = df['text'].progress_apply(lambda x: pt.get_avg_wordlength(x))\n",
    "        df['stopword_count'] = df['text'].progress_apply(lambda x: pt.get_stopwords_counts(x))\n",
    "        df['hashtag_count'] = df['text'].progress_apply(lambda x: pt.get_hashtag_counts(x))\n",
    "        df['mention_count'] = df['text'].progress_apply(lambda x: pt.get_mention_counts(x))\n",
    "        df['digit_counts'] = df['text'].progress_apply(lambda x: pt.get_digit_counts(x))\n",
    "        df['uppercase_count'] = df['text'].progress_apply(lambda x: pt.get_uppercase_counts(x))\n",
    "        df['emails_count'] = df['text'].progress_apply(lambda x: pt.get_emails(x))\n",
    "        df['urls_count'] = df['text'].progress_apply(lambda x: pt.get_urls(x))\n",
    "        df['punc_count'] = df['text'].progress_apply(lambda x: pt.get_punc_counts(x))\n",
    "        df[\"exclaimation_count\"] = df[\"text\"].progress_apply(lambda x: x.count(\"!\"))\n",
    "        df[\"questionmark_count\"] = df[\"text\"].progress_apply(lambda x: x.count(\"?\"))\n",
    "    \n",
    "    if pos:\n",
    "        print('Text Preprocessing: Developing POS tag count')\n",
    "        df[\"pos\"] = df[\"text\"].progress_apply(lambda x: pt.get_pos_tag(x))\n",
    "        df[\"pos_ADJ_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"ADJ\"))     #adjective\n",
    "        df[\"pos_ADP_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"ADP\"))     #adposition\n",
    "        df[\"pos_ADV_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"ADV\"))     #adverb\n",
    "        df[\"pos_AUX_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"AUX\"))     #auxiliary\n",
    "        df[\"pos_CCONJ_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"CCONJ\")) #coordinating conjunction\n",
    "        df[\"pos_DET_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"DET\"))     #determiner\n",
    "        df[\"pos_NOUN_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"NOUN\"))   #noun\n",
    "        df[\"pos_INTJ_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"INTJ\"))   #interjection\n",
    "        df[\"pos_NUM_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"NUM\"))     #numeral\n",
    "        df[\"pos_PART_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"PART\"))   #particle\n",
    "        df[\"pos_PRON_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"PRON\"))   #pronoun\n",
    "        df[\"pos_PROPN_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"PROPN\")) #proper noun\n",
    "        df[\"pos_PUNCT_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"PUNCT\")) #punctuation\n",
    "        df[\"pos_SCONJ_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"SCONJ\")) #subordinating conjunction\n",
    "        df[\"pos_SYM_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"SYM\"))     #symbol\n",
    "        df[\"pos_VERB_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"VERB\"))   #verb\n",
    "        df[\"pos_other_counts\"] = df[\"pos\"].progress_apply(lambda x: pt.get_pos_tag_counts(x,pos_tag=\"X\"))     #other\n",
    "    \n",
    "    if ner:\n",
    "        print('Text Preprocessing: Developing NER tag count')\n",
    "        df[\"ner\"] = df[\"text\"].progress_apply(lambda x: pt.get_ner(x))\n",
    "        ner_lst = nlp.pipe_labels['ner']\n",
    "        for ner in ner_lst:\n",
    "             df[\"ner_\"+ ner +\"_counts\"] =  df[\"ner\"].apply(lambda x: pt.get_ner_counts(x,ner))\n",
    "                \n",
    "    if remove_url:\n",
    "        print('Text Preprocessing: Remove URL')\n",
    "        df['text_check'] = df['text'].progress_apply(lambda x: pt.remove_urls(x))\n",
    "        \n",
    "    if remove_email:\n",
    "        print('Text Preprocessing: Remove email')\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: pt.remove_emails(x))\n",
    "        \n",
    "    if remove_user_mention:\n",
    "        print('Text Preprocessing: Remove user mention')\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: pt.remove_mention(x))\n",
    "    \n",
    "    if remove_html:\n",
    "        print('Text Preprocessing: Remove html element')\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: pt.remove_html_tags(x))\n",
    "        \n",
    "    if remove_space_single_char:\n",
    "        print('Text Preprocessing: Remove single spcae between single characters e.g F U C K')\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: pt.remove_space_single_chars(x))\n",
    "        \n",
    "    if normalize_elongated_char:\n",
    "        print('Text Preprocessing: Reduction of elongated characters')\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: pt.remove_elongated_chars(x))\n",
    "        \n",
    "    if normalize_emoji:\n",
    "        print('Text Preprocessing: Normalize and count emoji')\n",
    "        df['emoji_counts'] = df['text_check'].progress_apply(lambda x: pt.get_emoji_counts(x))\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: pt.convert_emojis(x))\n",
    "        \n",
    "        \n",
    "    if normalize_emoticon:\n",
    "        print('Text Preprocessing: Normalize and count emoticon')\n",
    "        df['emoticon_counts'] = df['text_check'].progress_apply(lambda x: pt.get_emoticon_counts(x))\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: pt.convert_emoticons(x))\n",
    "        \n",
    "        \n",
    "    if normalize_accented:\n",
    "        print('Text Preprocessing: Normalize accented character')\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: pt.remove_accented_chars(x))\n",
    "        \n",
    "    if lower_case:\n",
    "        print('Text Preprocessing: Convert to lower case')\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: str(x).lower())\n",
    "    \n",
    "    if normalize_slang:\n",
    "        print('Text Preprocessing: Normalize slang')\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: pt.slang_resolution(x))\n",
    "        \n",
    "    if normalize_badterm:\n",
    "        print('Text Preprocessing: Replace obfuscated bad term')\n",
    "        # unique words in vocab \n",
    "        unique_words = get_vocab(corpus= df['text_check'])\n",
    "        \n",
    "        # creating mapping dict \n",
    "        mapping_dict = create_profane_mapping(profane_words=term_badword_list,vocabulary=unique_words)\n",
    "        \n",
    "        df['text_check'] = replace_words(corpus=df['text_check'],\n",
    "                                                 mapping_dict=mapping_dict)\n",
    "        \n",
    "    if spelling_check:\n",
    "        print('Text Preprocessing: Spelling Check')\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: tool.correct(x))\n",
    "        tool.close()\n",
    "        \n",
    "    if normalize_contraction:\n",
    "        print('Text Preprocessing: Contraction to Expansion')\n",
    "        \n",
    "        # Special handling to prevent code from taking forever to run\n",
    "        hardcode_clean_50702 = df['text_check'].iloc[50702].replace(\"'d\",\" would\").replace(\"wasn't\",\"was not\").replace(\"wouldn't\",\"would not\").replace(\"'s\",\" is\").replace(\"'m\",\" am\")\n",
    "        df['text_check'].iloc[50702] = hardcode_clean_50702\n",
    "\n",
    "        hardcode_clean_107720 = df['text_check'].iloc[107720].replace(\"'d\",\" would\").replace(\"wasn't\",\"was not\").replace(\"wouldn't\",\"would not\")\n",
    "        df['text_check'].iloc[107720] = hardcode_clean_107720\n",
    "\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: ''.join(list(cont.expand_texts([x], precise=True))))\n",
    "    \n",
    "    if term_list:\n",
    "        print('Developing Binary Features for existence of terms by category')\n",
    "        df['term_absolute_counts'] = df['text_check'].progress_apply(lambda x: get_term_counts([x],category=term_absolute_list))\n",
    "        df['term_allness_counts'] = df['text_check'].progress_apply(lambda x: get_term_counts([x],category=term_allness_list))\n",
    "        df['term_badword_counts'] = df['text_check'].progress_apply(lambda x: get_term_counts([x],category=term_badword_list))\n",
    "        df['term_negation_counts'] = df['text_check'].progress_apply(lambda x: get_term_counts([x],category=term_negation_list))\n",
    "        df['term_diminisher_counts'] = df['text_check'].progress_apply(lambda x: get_term_counts([x],category=term_diminisher_list))\n",
    "        df['term_intensifier_counts'] = df['text_check'].progress_apply(lambda x: get_term_counts([x],category=term_intensifier_list))\n",
    "\n",
    "    if remove_numeric: \n",
    "        print('Text Preprocessing: Remove numeric')\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: pt.remove_numeric(x))\n",
    "        \n",
    "    if remove_punctuation:\n",
    "        print('Text Preprocessing: Remove punctuations')\n",
    "        df['text_check'] = df['text_check'].progress_apply(lambda x: pt.remove_special_chars(x))\n",
    "        \n",
    "    if remove_stopword:\n",
    "        print('Text Preprocessing: Remove stopword')\n",
    "        if keep_pronoun:\n",
    "            print('Text Preprocessing: and, keep Pronoun')\n",
    "        df[\"text_check\"] = df[\"text_check\"].progress_apply(lambda x: pt.remove_stopwords(x,keep_pronoun=keep_pronoun))\n",
    "        \n",
    "    # Remove multiple spaces\n",
    "    print('Text Preprocessing: Remove multiple spaces')\n",
    "    df['text_check'] = df['text_check'].progress_apply(lambda x: ' '.join(x.split()))\n",
    "    \n",
    "    if lemmatise:\n",
    "        print('Text Preprocessing: Lemmatization')\n",
    "        df[\"text_check\"] = df[\"text_check\"].progress_apply(lambda x: pt.make_base(x))\n",
    "        \n",
    "    # Make sure remove multiple spaces\n",
    "    # df['text_check'] = df['text_check'].progress_apply(lambda x: ' '.join(x.split()))\n",
    "    \n",
    "    # Make sure lower case for all again\n",
    "    df['text_check'] = df['text_check'].progress_apply(lambda x: str(x).lower())\n",
    "    \n",
    "    # Remove empty text after cleaning\n",
    "    print('Last Step: Remove empty text after preprocessing. Done')\n",
    "    df = df[~df['text_check'].isna()]\n",
    "    df = df[df['text_check'] != '']\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3183c661",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#ff6f69; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Output: Preprocessed and Cleaned Data</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82205cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Developing textual statistics from original text\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d27f1669df4482b1da03ae421f69d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2996435e770b49728bfd5395bb5087e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee60022965f4c00a7e46814a50dbff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6bd9d0a9ff4d18b8d04bb58114cb0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ef3b8631494fec96d2a24ff61f3262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f7c625a59146cf9de9f843792da74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e66a148e804a52b800b9f9c78d33bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf928763a65d4aabb823a96f68b8b67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc34f843bb9467aad7896b57f881972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35acf1c5ec494da1beccba66c7794541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19657a368a7e4e57b7daf891cffda720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c2d8052aec45d385a435dd85bbd0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e599e2005eb74ed882adca6fd893e04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Developing POS tag count\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8550ed40da48b596b7fad722faebbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb95bb748dc14daca8803cdfd92d1d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18969313f6d848849a9c13b46069bedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac7a85b94d845d6b230ce9e94f89d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6dc441c44ef4452ab7fc8e63a125668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e659d12d284496e9ed5063c8439e8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d18947fbbd4333a1b4fcaa49bcd961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1db6b7ae404438ab380256eeb64ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7562b7c98d4e92a72b3e1ee7aec13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4095bd1131434bceb8675b1ca78ccc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28dd770ab4b74eebb81e2752daa67129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8a6a467d2c410ba4e701e1cba40367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70448b2a98d64e46853c3a75516b5a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64126248cd4f4ed0aac55bbb4aed4200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486091a62b3b49e0b8a026dabd5f5ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281654760a5d44c7ba54b9647e2662f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9b636d837842ac94067691ec31466e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b974082b1bb4fd6b63d6a080416491f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Developing NER tag count\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ebb4dfa1404bf58f4a56d842f694c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Remove URL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c59d0bbfae4cec9fe14354092ab627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Remove email\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174cdc3fb8c2490aa081f91eb45a828c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Remove user mention\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9194ebc43d945f2b15be5fdd486f155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Remove html element\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b8d64996094b0a8513780f61ec510e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Remove single spcae between single characters e.g F U C K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3b4ae46c024ceaa68e41c7f26882ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Reduction of elongated characters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac56ba52abee485b8563ff5a44793bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Normalize and count emoji\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00530f9d93b489d93680e08ccdfc132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7927286a14174964a6dbcdf646ca387b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Normalize and count emoticon\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbe6e4e0e194a5d9319c67c9c0e6174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7222ce6205e49b9b51b0e56a52580db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Normalize accented character\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e246ffed0bf4298ac963f6ab16b90bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Convert to lower case\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c0573aa5f8441f8ecea25ac1bd1957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Normalize slang\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aab0971e5524d628032cd3f3e3da1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Replace obfuscated bad term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113694/113694 [00:00<00:00, 541277.61it/s]\n",
      "100%|██████████| 1921/1921 [03:45<00:00,  8.53it/s]\n",
      "100%|██████████| 113694/113694 [01:21<00:00, 1394.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Spelling Check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43ba75fb0da4165a3152fac8c67a92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Contraction to Expansion\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc47343ca1774b159fa26f7cb63c3320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n",
      "At least one of the documents had no words that were in the vocabulary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Developing Binary Features for existence of terms by category\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1267841eff4e62b074c64f0cba99c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4abbf8fbe2d4873ae91eb848c51596a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cc0ef7e91a48e59c6fdcc35a4da1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3a32725ef143288ba3b6835d60c99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc9c7bebdea4f1685c0a048d5ce3cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6794ac10e4294fa58b6874f5ac758811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Remove numeric\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69115a9f24e248b09232e2ac302b26b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Remove punctuations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241a09ef96cc45ba86d6bfd526d35f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Remove multiple spaces\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df2b2f225594f1990623dc37c705aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Lemmatization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f140ddf3b2b4277a1bf62b9839332cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f2d869f0434a658a9ade1040007061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Step: Remove empty text after preprocessing. Done\n"
     ]
    }
   ],
   "source": [
    "bully_data_clean_with_stopword = text_preprocessing_pipeline(\n",
    "                                    df=bully_data,\n",
    "                                    textual_statistics=True,\n",
    "                                    remove_url=True,\n",
    "                                    remove_email=True,\n",
    "                                    remove_user_mention=True,\n",
    "                                    remove_html=True,\n",
    "                                    remove_space_single_char=True,\n",
    "                                    normalize_elongated_char=True,\n",
    "                                    normalize_emoji=True,\n",
    "                                    normalize_emoticon=True,\n",
    "                                    normalize_accented=True,\n",
    "                                    lower_case=True,\n",
    "                                    normalize_slang=True,\n",
    "                                    normalize_badterm=True,\n",
    "                                    spelling_check=True,\n",
    "                                    normalize_contraction=True,\n",
    "                                    term_list=True,\n",
    "                                    remove_numeric=True,\n",
    "                                    remove_stopword=False, # Keep stopwords\n",
    "                                    keep_pronoun=False,  # Keep pronoun\n",
    "                                    remove_punctuation=True,\n",
    "                                    pos=True,\n",
    "                                    ner=True,\n",
    "                                    lemmatise=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19470ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bully_data_clean_with_stopword_base1 =  bully_data_clean_with_stopword.copy()\n",
    "bully_data_clean_with_stopword_base2 =  bully_data_clean_with_stopword.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7be718eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Remove stopword\n",
      "Text Preprocessing: and, keep Pronoun\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01103e6338484e8992fbd25707019eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Remove multiple spaces\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95028f99a24b4693bd8ba8d9f504318e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206df1a3fb254d51b7f7923d5f077b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Step: Remove empty text after preprocessing. Done\n"
     ]
    }
   ],
   "source": [
    "bully_data_clean_no_stopword_pronoun = text_preprocessing_pipeline(\n",
    "                                            df=bully_data_clean_with_stopword_base1,\n",
    "                                            remove_stopword=True, # Remove stopwords\n",
    "                                            keep_pronoun=True) # But keep pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc007383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Remove stopword\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5487b866e34e4adca19a6245e7f456b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing: Remove multiple spaces\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b1933388944c18a60f08b7cc39283b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78dde768bb674ff88f89ac0aa2c5416d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Step: Remove empty text after preprocessing. Done\n"
     ]
    }
   ],
   "source": [
    "bully_data_clean_no_stopword_all = text_preprocessing_pipeline(\n",
    "                                        df=bully_data_clean_with_stopword_base2,\n",
    "                                        remove_stopword=True, # Remove all stopwords\n",
    "                                        keep_pronoun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab397fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bully_data_clean_with_stopword.to_csv('bully_data_clean_with_stopword.csv')\n",
    "bully_data_clean_no_stopword_pronoun.to_csv('bully_data_clean_no_stopword_pronoun.csv')\n",
    "bully_data_clean_no_stopword_all.to_csv('bully_data_clean_no_stopword_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2234fe",
   "metadata": {},
   "source": [
    "<h1><center>- END Preprocessing and Cleaning -</center></h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
