{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30dbc463",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#fff; color:white; padding:0px 10px; border-radius:5px;\"><h1 style='margin:15px 15px; color:#5d3a8e; font-size:40px'> 3.3 Feature Extraction (PyTorch HuggingFace Transformer)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f7c9c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'> Table of Content</h2>\n",
    "</div>\n",
    "\n",
    "* [Required Libraries and Modules](#Required-Libraries-and-Modules)\n",
    "* [Import Clean Text Data](#Import-Clean-Text-Data)\n",
    "* [BERT and its variants Word Embeddings PyTorch HuggingFace Transformers](#BERT-and-its-variants-Word-Embeddings-PyTorch-HuggingFace-Transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f4b73d",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "\n",
    "**How can I combine different features?**\n",
    "\n",
    "Usually, if possible, you'd want to keep your matrice sparse as long as possible as it saves a lot of memory. That's why there are sparse matrices after all, otherwise, why bother? So, even if your classifier requires you to use dense input, you might want to keep the TFIDF features as sparse, and add the other features to them in a sparse format. And then only, make the matrix dense.\n",
    "\n",
    "To do that, you could use scipy.sparse.hstack. It combines two sparse matrices together by column. scipy.sparse.vstack also exists. And of course, scipy also has the non-sparse version scipy.hstack and scipy.vstack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed65ae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Required Libraries and Modules</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd9ed739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "%matplotlib inline\n",
    "\n",
    "# Begin Python Imports\n",
    "import datetime, warnings, scipy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from scipy.sparse import hstack\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# Progress bar\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "# Feature Extraction -  Textual Features\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score, \n",
    "    accuracy_score, \n",
    "    confusion_matrix, \n",
    "    classification_report, \n",
    "    plot_confusion_matrix,\n",
    "    plot_precision_recall_curve\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b232ab",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Import Clean Text Data</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4949d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# Note: Change the name of data set used for feature creation\n",
    "###############################################################\n",
    "task = 'bully_binary_classification'\n",
    "data_set='bully_data_clean_no_stopword_all'\n",
    "    \n",
    "    \n",
    "###################\n",
    "# Import Data Set #\n",
    "###################\n",
    "bully_data_cleaned = pd.read_csv(data_set+'.csv', encoding='utf8')\n",
    "bully_data_cleaned = bully_data_cleaned.drop(['ner','pos','Unnamed: 0'],axis=1)\n",
    "bully_data_cleaned = bully_data_cleaned[~bully_data_cleaned['text_check'].isna()]\n",
    "bully_data_cleaned = bully_data_cleaned[bully_data_cleaned['text_check'] != \"\"]\n",
    "# bully_data_cleaned = bully_data_cleaned[bully_data_cleaned['role']!='None']\n",
    "bully_data_cleaned = bully_data_cleaned.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e98fa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107101 entries, 0 to 107100\n",
      "Data columns (total 64 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   tag                      107101 non-null  object \n",
      " 1   text                     107101 non-null  object \n",
      " 2   label                    107101 non-null  object \n",
      " 3   role                     107101 non-null  object \n",
      " 4   harmfulness_score        107101 non-null  int64  \n",
      " 5   oth_language             107101 non-null  int64  \n",
      " 6   file_index               107101 non-null  object \n",
      " 7   word_count               107101 non-null  int64  \n",
      " 8   char_count               107101 non-null  int64  \n",
      " 9   avg_word_len             107101 non-null  float64\n",
      " 10  stopword_count           107101 non-null  int64  \n",
      " 11  hashtag_count            107101 non-null  int64  \n",
      " 12  mention_count            107101 non-null  int64  \n",
      " 13  digit_counts             107101 non-null  int64  \n",
      " 14  uppercase_count          107101 non-null  int64  \n",
      " 15  emails_count             107101 non-null  int64  \n",
      " 16  urls_count               107101 non-null  int64  \n",
      " 17  punc_count               107101 non-null  int64  \n",
      " 18  exclaimation_count       107101 non-null  int64  \n",
      " 19  questionmark_count       107101 non-null  int64  \n",
      " 20  pos_ADJ_counts           107101 non-null  int64  \n",
      " 21  pos_ADP_counts           107101 non-null  int64  \n",
      " 22  pos_ADV_counts           107101 non-null  int64  \n",
      " 23  pos_AUX_counts           107101 non-null  int64  \n",
      " 24  pos_CCONJ_counts         107101 non-null  int64  \n",
      " 25  pos_DET_counts           107101 non-null  int64  \n",
      " 26  pos_NOUN_counts          107101 non-null  int64  \n",
      " 27  pos_INTJ_counts          107101 non-null  int64  \n",
      " 28  pos_NUM_counts           107101 non-null  int64  \n",
      " 29  pos_PART_counts          107101 non-null  int64  \n",
      " 30  pos_PRON_counts          107101 non-null  int64  \n",
      " 31  pos_PROPN_counts         107101 non-null  int64  \n",
      " 32  pos_PUNCT_counts         107101 non-null  int64  \n",
      " 33  pos_SCONJ_counts         107101 non-null  int64  \n",
      " 34  pos_SYM_counts           107101 non-null  int64  \n",
      " 35  pos_VERB_counts          107101 non-null  int64  \n",
      " 36  pos_other_counts         107101 non-null  int64  \n",
      " 37  ner_CARDINAL_counts      107101 non-null  int64  \n",
      " 38  ner_DATE_counts          107101 non-null  int64  \n",
      " 39  ner_EVENT_counts         107101 non-null  int64  \n",
      " 40  ner_FAC_counts           107101 non-null  int64  \n",
      " 41  ner_GPE_counts           107101 non-null  int64  \n",
      " 42  ner_LANGUAGE_counts      107101 non-null  int64  \n",
      " 43  ner_LAW_counts           107101 non-null  int64  \n",
      " 44  ner_LOC_counts           107101 non-null  int64  \n",
      " 45  ner_MONEY_counts         107101 non-null  int64  \n",
      " 46  ner_NORP_counts          107101 non-null  int64  \n",
      " 47  ner_ORDINAL_counts       107101 non-null  int64  \n",
      " 48  ner_ORG_counts           107101 non-null  int64  \n",
      " 49  ner_PERCENT_counts       107101 non-null  int64  \n",
      " 50  ner_PERSON_counts        107101 non-null  int64  \n",
      " 51  ner_PRODUCT_counts       107101 non-null  int64  \n",
      " 52  ner_QUANTITY_counts      107101 non-null  int64  \n",
      " 53  ner_TIME_counts          107101 non-null  int64  \n",
      " 54  ner_WORK_OF_ART_counts   107101 non-null  int64  \n",
      " 55  text_check               107101 non-null  object \n",
      " 56  emoji_counts             107101 non-null  int64  \n",
      " 57  emoticon_counts          107101 non-null  int64  \n",
      " 58  term_absolute_counts     107101 non-null  int64  \n",
      " 59  term_allness_counts      107101 non-null  int64  \n",
      " 60  term_badword_counts      107101 non-null  int64  \n",
      " 61  term_negation_counts     107101 non-null  int64  \n",
      " 62  term_diminisher_counts   107101 non-null  int64  \n",
      " 63  term_intensifier_counts  107101 non-null  int64  \n",
      "dtypes: float64(1), int64(57), object(6)\n",
      "memory usage: 52.3+ MB\n"
     ]
    }
   ],
   "source": [
    "bully_data_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7fa8fc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>BERT and its variants Word Embeddings PyTorch HuggingFace Transformers</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab687d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# Word Embedding (BERT and its variants) HuggingFace Hub #\n",
    "##########################################################\n",
    "\n",
    "def get_bert_features_huggingface(df=bully_data_cleaned,\n",
    "                                  type= \"distilbert\",\n",
    "                                  chunk_size=50):\n",
    "    \n",
    "    '''\n",
    "    -------------\n",
    "     Description \n",
    "    -------------\n",
    "    Umbrella Function to extract bert and its variants word embedding features\n",
    "    from PyTorch Huggingface Hub\n",
    "    \n",
    "    ------------\n",
    "     Parameters\n",
    "    ------------\n",
    "\n",
    "    df: data frame name\n",
    "    type: specify the type of bert or its variants\n",
    "    - mobilebert\n",
    "    - roberta\n",
    "    - distillbert\n",
    "    \n",
    "    chunk_size: size of chunk sets\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Selection of model, tokenizer, and pretrained model\n",
    "    if type == \"distilbert\":\n",
    "        dimension=768\n",
    "        model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "    elif type == \"roberta\":\n",
    "        dimension=768\n",
    "        model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-base')\n",
    "\n",
    "    elif type == \"mobilebert\":\n",
    "        dimension=512\n",
    "        model_class, tokenizer_class, pretrained_weights = (ppb.MobileBertModel, ppb.MobileBertTokenizer, 'google/mobilebert-uncased')\n",
    "\n",
    "             \n",
    "    # Load pretrained model/tokenizer\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "    model = model_class.from_pretrained(pretrained_weights).to('cuda:0')\n",
    "\n",
    "\n",
    "    # Preprocess\n",
    "    tokenized = df['text_check'].progress_apply(lambda x: tokenizer.encode(x, truncation=True,max_length=512,add_special_tokens=True))\n",
    "\n",
    "\n",
    "    # Check maximum length of all inputs\n",
    "    max_len = 0\n",
    "    for i in tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "    print(max_len)\n",
    "    \n",
    "    \n",
    "    # Padding - Insert padded [0]\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "\n",
    "    # Attention mask\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "\n",
    "    # Use cuda to run with GPU\n",
    "    input_ids = torch.tensor(padded).to('cuda:0')  \n",
    "    attention_mask = torch.tensor(attention_mask).to('cuda:0')\n",
    "\n",
    "    \n",
    "    \n",
    "    ##################\n",
    "    # Loop by chunks #\n",
    "    ##################\n",
    "    \n",
    "    bert_embedding=np.empty((0, dimension), float)\n",
    "    for i in tqdm(np.arange(0,df.shape[0],chunk_size)):\n",
    "        with torch.no_grad():\n",
    "            last_hidden_states = model(input_ids[i:i+chunk_size], attention_mask=attention_mask[i:i+chunk_size])\n",
    "\n",
    "        features = last_hidden_states[0][:,0,:].cpu().data.numpy()\n",
    "        bert_embedding = np.vstack((bert_embedding,features))\n",
    "        \n",
    "    bert_embedding_sparse = sparse.csr_matrix(bert_embedding)\n",
    "    return bert_embedding_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468efcf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Combination of Features</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7960c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# DistilBert #\n",
    "##############\n",
    "print(\"Generating DistilBertEmbedding features\")\n",
    "# About 1.5 hour\n",
    "X_DistilBertEmbedding=get_bert_features_huggingface(df=bully_data_cleaned,\n",
    "                                  type=\"distilbert\",\n",
    "                                  chunk_size=50)\n",
    "\n",
    "with open(task+\"\\\\\"+data_set+\"\\\\features\\\\X_DistilBertEmbedding.pkl\",'wb') as f:\n",
    "    pickle.dump(X_DistilBertEmbedding, f)\n",
    "    \n",
    "print(\"Shape: \"+str(X_DistilBertEmbedding.shape)) # check shape   \n",
    "\n",
    "del X_DistilBertEmbedding # to free up memory\n",
    "gc.collect()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# RoBerta #\n",
    "###########\n",
    "print()\n",
    "print(\"Generating RoBertaEmbedding features\")\n",
    "# About 2 hour\n",
    "X_RoBertaEmbedding=get_bert_features_huggingface(df=bully_data_cleaned,\n",
    "                                  type=\"roberta\",\n",
    "                                  chunk_size=20)\n",
    "\n",
    "with open(task+\"\\\\\"+data_set+\"\\\\features\\\\X_RoBertaEmbedding.pkl\",'wb') as f:\n",
    "    pickle.dump(X_RoBertaEmbedding, f)\n",
    "    \n",
    "print(\"Shape: \"+str(X_RoBertaEmbedding.shape)) # check shape   \n",
    "    \n",
    "del X_RoBertaEmbedding # to free up memory\n",
    "gc.collect()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f2702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# mobileBert #\n",
    "##############\n",
    "print()\n",
    "print(\"Generating mobileBertEmbedding features\")\n",
    "# About 35 minutes\n",
    "X_mobileBertEmbedding=get_bert_features_huggingface(df=bully_data_cleaned,\n",
    "                                  type=\"mobilebert\",\n",
    "                                  chunk_size=40)\n",
    "\n",
    "with open(task+\"\\\\\"+data_set+\"\\\\features\\\\X_mobileBertEmbedding.pkl\",'wb') as f:\n",
    "    pickle.dump(X_mobileBertEmbedding, f)\n",
    "    \n",
    "print(\"Shape: \"+str(X_mobileBertEmbedding.shape)) # check shape   \n",
    "    \n",
    "del X_mobileBertEmbedding # to free up memory\n",
    "gc.collect()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
